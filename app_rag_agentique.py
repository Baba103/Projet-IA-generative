# ğŸ¨ Interface Streamlit COMPLÃˆTE avec Architecture Agentique - RAG v4.2

import streamlit as st
import os
import time
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
from collections import deque

# Configuration
st.set_page_config(
    page_title="RAG Multi-Documents Agentique",
    page_icon="ğŸ¤–",
    layout="wide"
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CACHE_PATH = "C:/Users/hp/OneDrive/Desktop/dq/RAG_Cache_Incremental"
GROQ_API_KEY = "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"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASSES AGENTIQUES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConversationMemory:
    def __init__(self, max_turns=10):
        self.max_turns = max_turns
        self.history = deque(maxlen=max_turns)
    
    def add(self, question, answer):
        self.history.append({
            "question": question,
            "answer": answer,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_context(self, n=3):
        recent = list(self.history)[-n:]
        context = []
        for turn in recent:
            context.append(f"Q: {turn['question']}\\nR: {turn['answer'][:200]}")
        return "\\n\\n".join(context)
    
    def clear(self):
        self.history.clear()

class EntityTracker:
    def __init__(self):
        self.last_mentioned = {}
        self.mention_order = []
    
    def extract_entities(self, text):
        # Articles
        articles = re.findall(r'[Aa]rticle\\s+(\\d+)', text)
        if articles:
            self.last_mentioned["article"] = articles[-1]
            self.mention_order.append(("article", articles[-1]))
        
        # Directions/Services
        directions = re.findall(r'(?:Direction|Service)\\s+(?:de\\s+)?(?:la\\s+)?([A-ZÃ€-Ã¿\\s]+)', text)
        cleaned = [d.strip() for d in directions if len(d.strip()) > 3]
        if cleaned:
            self.last_mentioned["direction"] = cleaned[-1]
            self.mention_order.append(("direction", cleaned[-1]))
    
    def resolve(self, pronoun):
        p = pronoun.lower()
        if p in ["il", "elle", "le", "la"]:
            for etype in ["article", "direction"]:
                if etype in self.last_mentioned:
                    return f"{etype.capitalize()} {self.last_mentioned[etype]}"
        return pronoun
    
    def get_first(self):
        if self.mention_order:
            etype, value = self.mention_order[0]
            return f"{etype.capitalize()} {value}"
        return ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INITIALISATION RAG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_resource
def init_rag():
    """Initialiser systÃ¨me RAG agentique"""
    from sentence_transformers import SentenceTransformer
    import chromadb
    from groq import Groq
    
    with st.spinner("ğŸ”Œ Chargement systÃ¨me agentique..."):
        # ChromaDB
        chroma_path = os.path.join(CACHE_PATH, "chroma_db")
        client = chromadb.PersistentClient(path=chroma_path)
        collection = client.get_collection(name="journal_officiel_incremental")
        
        # Embedding
        embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        
        # Groq
        groq_client = Groq(api_key=GROQ_API_KEY)
        
    return collection, embedding_model, groq_client

try:
    collection, embedding_model, groq_client = init_rag()
    st.success(f"âœ… SystÃ¨me agentique chargÃ©: {collection.count():,} documents")
except Exception as e:
    st.error(f"âŒ Erreur: {e}")
    st.stop()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SESSION STATE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if "messages" not in st.session_state:
    st.session_state.messages = []

if "conversation_memory" not in st.session_state:
    st.session_state.conversation_memory = ConversationMemory(max_turns=10)

if "entity_tracker" not in st.session_state:
    st.session_state.entity_tracker = EntityTracker()

if "stats" not in st.session_state:
    st.session_state.stats = {
        "questions": 0,
        "avg_confidence": 0,
        "coreferences_resolved": 0,
        "web_fallbacks": 0,
        "start_time": datetime.now()
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AGENTS RAG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def orchestrator_agent(question, memory, entity_tracker):
    """Agent Orchestrateur - Enrichissement et rÃ©solution corÃ©fÃ©rences"""
    
    context = memory.get_context(n=2)
    
    # DÃ©tecter pronoms
    pronouns_pattern = r'\\b(il|elle|le|la|ses|premier|premiÃ¨re|dernier|derniÃ¨re)\\b'
    pronouns = re.findall(pronouns_pattern, question, re.IGNORECASE)
    
    enriched = question
    resolutions = {}
    
    for pronoun in pronouns:
        p = pronoun.lower()
        if p in ["premier", "premiÃ¨re"]:
            resolution = entity_tracker.get_first()
        else:
            resolution = entity_tracker.resolve(pronoun)
        
        if resolution and resolution != pronoun:
            enriched = enriched.replace(pronoun, resolution)
            resolutions[pronoun] = resolution
    
    entity_tracker.extract_entities(question + " " + enriched)
    
    return enriched, context, resolutions

def search_agent(query, year=None, source=None, top_k=10):
    """Agent de Recherche - Recherche sÃ©mantique dans base"""
    
    query_embedding = embedding_model.encode([query], convert_to_numpy=True)
    
    where_filter = {}
    if year:
        where_filter["year"] = str(year)
    if source:
        where_filter["source_file"] = {"$contains": source}
    
    results = collection.query(
        query_embeddings=query_embedding.tolist(),
        n_results=top_k,
        include=["documents", "metadatas", "distances"],
        where=where_filter if where_filter else None
    )
    
    if not results["documents"][0]:
        return [], 0.0
    
    docs = []
    distances = results["distances"][0]
    scores = [1 / (1 + d) for d in distances]
    confidence = sum(scores) / len(scores)
    
    for doc, meta, score in zip(results["documents"][0], results["metadatas"][0], scores):
        docs.append({
            "text": doc,
            "source": meta.get("source_file", "Unknown"),
            "year": meta.get("year", ""),
            "score": score,
            "metadata": meta
        })
    
    return docs, confidence

def web_fallback_agent(question):
    """Agent Web Fallback - Recherche DuckDuckGo si confiance faible"""
    
    try:
        import requests
        from bs4 import BeautifulSoup
        
        # Recherche DuckDuckGo
        url = f"https://html.duckduckgo.com/html/?q={question}"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=5)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            results = soup.find_all('a', class_='result__a', limit=3)
            
            web_results = []
            for result in results:
                title = result.get_text()
                link = result.get('href', '')
                web_results.append({"title": title, "link": link})
            
            return web_results
        
    except Exception as e:
        pass
    
    return []

def synthesis_agent(question, docs, context):
    """Agent de SynthÃ¨se - GÃ©nÃ©ration rÃ©ponse avec Groq"""
    
    context_str = "\\n\\n".join([f"[Doc {i}] {d['text'][:500]}" for i, d in enumerate(docs[:5], 1)])
    
    prompt = f"""Tu es un assistant juridique expert.

SOURCES DOCUMENTAIRES:
{context_str}

CONTEXTE CONVERSATIONNEL:
{context[:300] if context else 'Aucun'}

QUESTION: {question}

INSTRUCTIONS:
- RÃ©ponds de maniÃ¨re prÃ©cise et structurÃ©e
- Utilise des points â€¢ pour les listes
- Cite les sources quand pertinent
- Si info manquante, indique-le clairement

RÃ‰PONSE:"""
    
    try:
        completion = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"âŒ Erreur Groq: {e}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SIDEBAR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

with st.sidebar:
    st.title("âš™ï¸ Configuration")
    st.markdown("---")
    
    # Filtres
    st.markdown("### ğŸ” Filtres")
    year = st.selectbox("ğŸ“… AnnÃ©e", ["Toutes"] + [str(y) for y in range(2025, 2016, -1)])
    source = st.text_input("ğŸ“„ Source", placeholder="Ex: 1389")
    
    st.markdown("---")
    
    # Stats
    st.markdown("### ğŸ“Š Session")
    st.metric("Questions", st.session_state.stats["questions"])
    
    if st.session_state.stats["questions"] > 0:
        avg = st.session_state.stats["avg_confidence"] / st.session_state.stats["questions"]
        st.metric("Confiance Moy.", f"{avg:.0%}")
    
    st.metric("CorÃ©fÃ©rences", st.session_state.stats["coreferences_resolved"])
    st.metric("Fallbacks Web", st.session_state.stats["web_fallbacks"])
    
    duration = (datetime.now() - st.session_state.stats["start_time"]).seconds // 60
    st.caption(f"â±ï¸ Session: {duration} min")
    
    st.markdown("---")
    
    if st.button("ğŸ”„ Nouvelle Conversation", use_container_width=True):
        st.session_state.messages = []
        st.session_state.conversation_memory.clear()
        st.session_state.entity_tracker = EntityTracker()
        st.rerun()
    
    st.markdown("---")
    
    with st.expander("ğŸ¤– Architecture Agentique"):
        st.markdown("""
        **Agents Actifs:**
        
        1. ğŸ¯ **Orchestrator**
           - Enrichissement contexte
           - RÃ©solution corÃ©fÃ©rences
           
        2. ğŸ” **Search Agent**
           - Recherche sÃ©mantique
           - Calcul confiance
           
        3. ğŸŒ **Web Fallback**
           - Si confiance < 50%
           - DuckDuckGo
           
        4. âœï¸ **Synthesis Agent**
           - GÃ©nÃ©ration Groq
           - Citations sources
        """)
    
    with st.expander("â„¹ï¸ Ã€ Propos"):
        st.markdown("""
        **RAG Agentique v4.2**
        
        - ğŸ“š ~224 PDFs
        - ğŸ“Š 40,021 chunks
        - ğŸ“… 2017-2025
        - ğŸ¤– 4 agents spÃ©cialisÃ©s
        """)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.title("ğŸ¤– RAG Multi-Documents Agentique")
st.caption("ğŸ’» Architecture avec 4 Agents SpÃ©cialisÃ©s | MÃ©moire Conversationnelle | RÃ©solution CorÃ©fÃ©rences")

# Historique
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        if "meta" in msg and msg["role"] == "assistant":
            cols = st.columns(4)
            cols[0].caption(f"ğŸ“Š {msg['meta']['conf']:.0%}")
            cols[1].caption(f"ğŸ“„ {msg['meta']['sources']} sources")
            cols[2].caption(f"â±ï¸ {msg['meta']['time']:.1f}s")
            if msg['meta'].get('coreferences'):
                cols[3].caption(f"ğŸ”„ {len(msg['meta']['coreferences'])} corÃ©f.")

# Input
if prompt := st.chat_input("ğŸ’¬ Votre question..."):
    
    # User message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Assistant response
    with st.chat_message("assistant"):
        placeholder = st.empty()
        status_placeholder = st.empty()
        
        start = time.time()
        
        # 1. Orchestration
        status_placeholder.info("ğŸ¯ Orchestrator: Enrichissement question...")
        enriched_q, context, resolutions = orchestrator_agent(
            prompt, 
            st.session_state.conversation_memory,
            st.session_state.entity_tracker
        )
        
        if resolutions:
            status_placeholder.success(f"ğŸ”„ CorÃ©fÃ©rences rÃ©solues: {resolutions}")
            st.session_state.stats["coreferences_resolved"] += len(resolutions)
            time.sleep(1)
        
        # 2. Recherche
        status_placeholder.info("ğŸ” Search Agent: Recherche dans base...")
        year_param = None if year == "Toutes" else year
        source_param = source if source else None
        docs, confidence = search_agent(enriched_q, year_param, source_param)
        
        # 3. Fallback Web si confiance faible OU aucun rÃ©sultat
        web_used = False
        if (confidence < 0.6 or not docs):  # â† Seuil augmentÃ© Ã  60% + activation si vide
            status_placeholder.warning("ğŸŒ Web Fallback: Confiance faible ou pas de rÃ©sultats, recherche web...")
            web_results = web_fallback_agent(prompt)
            if web_results:
                web_used = True
                st.session_state.stats["web_fallbacks"] += 1
                # Afficher rÃ©sultats web
                with st.expander("ğŸŒ RÃ©sultats Web"):
                    for i, res in enumerate(web_results, 1):
                        st.write(f"{i}. [{res['title']}]({res['link']})")
                time.sleep(1)
        
        # 4. SynthÃ¨se
        if docs:
            status_placeholder.info("âœï¸ Synthesis Agent: GÃ©nÃ©ration rÃ©ponse...")
            answer = synthesis_agent(prompt, docs, context)
            exec_time = time.time() - start
            
            # Affichage
            status_placeholder.empty()
            placeholder.markdown(answer)
            
            cols = st.columns(4)
            color = "ğŸŸ¢" if confidence > 0.7 else "ğŸŸ¡" if confidence > 0.5 else "ğŸ”´"
            cols[0].caption(f"{color} {confidence:.0%}")
            cols[1].caption(f"ğŸ“„ {len(docs)} sources")
            cols[2].caption(f"â±ï¸ {exec_time:.1f}s")
            if resolutions:
                cols[3].caption(f"ğŸ”„ {len(resolutions)} corÃ©f.")
            
            if web_used:
                st.info("ğŸŒ Fallback web activÃ© (confiance initiale faible)")
            
            # Sauvegarder
            st.session_state.messages.append({
                "role": "assistant",
                "content": answer,
                "meta": {
                    "conf": confidence,
                    "sources": len(docs),
                    "time": exec_time,
                    "coreferences": resolutions
                }
            })
            
            # MÃ©moire
            st.session_state.conversation_memory.add(prompt, answer)
            st.session_state.entity_tracker.extract_entities(prompt + " " + answer)
            
            # Stats
            st.session_state.stats["questions"] += 1
            st.session_state.stats["avg_confidence"] += confidence
            
        else:
            status_placeholder.empty()
            placeholder.error("âŒ Aucun rÃ©sultat trouvÃ©")
